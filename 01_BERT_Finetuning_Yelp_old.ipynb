{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_BERT_Finetuning_Yelp.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyODYBwnBmy4t01ESAs4xN+H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"28f246f8847845cd80da00dfcff6ccce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_06df6f88044b4cfbb558d6fa5aea4659","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_afa40917c1f04a87b91cd66e7e4b1bca","IPY_MODEL_8082ce4c7b7a4081a7ddac0a87678203"]}},"06df6f88044b4cfbb558d6fa5aea4659":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"afa40917c1f04a87b91cd66e7e4b1bca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_28915ee20597455a9acc820a6f4cc872","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cd26a6a9116c48c7aaa7ffc422752d5c"}},"8082ce4c7b7a4081a7ddac0a87678203":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_09fd72e30b234a3aa782958684f385d0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 1.94MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bad4a014333f478c9ff254caf98050a7"}},"28915ee20597455a9acc820a6f4cc872":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cd26a6a9116c48c7aaa7ffc422752d5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"09fd72e30b234a3aa782958684f385d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bad4a014333f478c9ff254caf98050a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aaf4f27ffa0d46b595cea779853f7e19":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c3a8348a1d6040b89055f15f841a1919","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ba655ea92ca34aca9c3c7f261f9d692d","IPY_MODEL_4859fc421dfe4626b28e508886558a2e"]}},"c3a8348a1d6040b89055f15f841a1919":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba655ea92ca34aca9c3c7f261f9d692d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5bd5e898c14446d48cca0b79ccca019e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_77ce6c600c7c4c47804580c6cd88b402"}},"4859fc421dfe4626b28e508886558a2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_00bb7913867049d2b30b8c4528733c54","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:08&lt;00:00, 50.7B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_849690a463f944e38279cf66a8e17fa9"}},"5bd5e898c14446d48cca0b79ccca019e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"77ce6c600c7c4c47804580c6cd88b402":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"00bb7913867049d2b30b8c4528733c54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"849690a463f944e38279cf66a8e17fa9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4651ed07c8c498ab05eb9c772bede82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_83844f0e5e204353a67e61d5767d5147","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_419563b0b43f40cbaca264873dea672e","IPY_MODEL_0b4e9a74470c44f0b56b5c2d84abe2f8"]}},"83844f0e5e204353a67e61d5767d5147":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"419563b0b43f40cbaca264873dea672e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_afdbf58b0c7943aa871dbe898761590e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_69726cec0dcc4c9fa546df2b5d924d93"}},"0b4e9a74470c44f0b56b5c2d84abe2f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ad2ead213bfb4330bd344248af798cea","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:08&lt;00:00, 53.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1712fec3b5df4621ab47de098022a095"}},"afdbf58b0c7943aa871dbe898761590e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"69726cec0dcc4c9fa546df2b5d924d93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ad2ead213bfb4330bd344248af798cea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1712fec3b5df4621ab47de098022a095":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a278dea474e5430a9f0df438522155ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_98011c1395434013ad83377d8e4e85b2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2a6ae962ab3545e99f2877f7aa404c22","IPY_MODEL_fa7256265f1b41f699d9ef01459ac09b"]}},"98011c1395434013ad83377d8e4e85b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2a6ae962ab3545e99f2877f7aa404c22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_86ed618eaed44ab0addc07a9f26c23a9","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f48c90eebc304d5c81618f7d45398a4a"}},"fa7256265f1b41f699d9ef01459ac09b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_77360e69cbff4423b9e4b5ffbac729b4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10000/10000 [03:02&lt;00:00, 54.73it/s, NLL=0.832]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_396702d2aae34ed69334ab4c1ca575f3"}},"86ed618eaed44ab0addc07a9f26c23a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f48c90eebc304d5c81618f7d45398a4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"77360e69cbff4423b9e4b5ffbac729b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"396702d2aae34ed69334ab4c1ca575f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8c56834132a140d7bed8c3b376962f5e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_53f2dfe5c935476abcdb0ddc33dbc09f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3b309a4776874502a65f365c75867264","IPY_MODEL_42943c336b1f47b5a92d3a5f0b5478eb"]}},"53f2dfe5c935476abcdb0ddc33dbc09f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3b309a4776874502a65f365c75867264":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cb9c8e35d27c4065a6cbbf72acff53da","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9b3f8657a79f45d4806bb3e0bc890a10"}},"42943c336b1f47b5a92d3a5f0b5478eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b7cf1a38d70e488583d0e40f60ad1441","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10000/10000 [03:00&lt;00:00, 55.55it/s, NLL=0.805]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_15b9c64abdcd40b4adffd7f5069d5b96"}}}}},"cells":[{"cell_type":"code","metadata":{"id":"7nWHsofSQcVx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1596291152869,"user_tz":240,"elapsed":1325,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"5e1d57c7-7d1b-4903-8f75-375e30b38f31"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sat Aug  1 14:12:32 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ey9EoCyDRClP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":595},"executionInfo":{"status":"ok","timestamp":1596291162995,"user_tz":240,"elapsed":8190,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"2c8c9dc8-bf51-44af-d7d3-28317c7d9fa6"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 2.9MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 10.3MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 38.6MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 46.3MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=439db0daf91233c038ba9385534c922c31a929bede038c8175ec8e2589fcaa8b\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z1IOsfcARGHG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1596291166961,"user_tz":240,"elapsed":5618,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"027bbb53-3d24-4552-9e80-ab77da2a3918"},"source":["!pip install tensorboardX"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tensorboardX\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n","\r\u001b[K     |█                               | 10kB 16.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (49.2.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sg6cUKDBPUyr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1596291170787,"user_tz":240,"elapsed":7831,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"aeda5d37-6956-462e-eb18-a5a9f5303c2a"},"source":["!pip install ujson"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting ujson\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/0a/35e07ebe48f0c2a23c316d92c2e26eade75e00a3df0758be57e7804bfbf0/ujson-3.0.0-cp36-cp36m-manylinux1_x86_64.whl (176kB)\n","\r\u001b[K     |█▉                              | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 2.8MB/s \n","\u001b[?25hInstalling collected packages: ujson\n","Successfully installed ujson-3.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DVULomjaRIOR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1596291186161,"user_tz":240,"elapsed":21499,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"8ca29e50-a34e-492a-dd90-c4d8bf148807"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RXScLCjxSDTl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291188783,"user_tz":240,"elapsed":5334,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["!unzip -q \"/content/gdrive/My Drive/Yelp_Sentiment_Analysis/dataset.zip\" -d '/content'"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QUZaYI-8SYG0","colab_type":"text"},"source":["**Fetch data and Preprocess**"]},{"cell_type":"code","metadata":{"id":"Mt5R90j_SUd-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291194846,"user_tz":240,"elapsed":10468,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["import random\n","import numpy as np\n","import json\n","from collections import Counter\n","from tqdm import tqdm\n","import re\n","from transformers import BertTokenizer, BertModel"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"eOO_PotSVwep","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291194850,"user_tz":240,"elapsed":9949,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["# does data cleaning for inital text\n","def process_file(filename, data_type):\n","    print(f\"Pre-processing {data_type} examples...\")\n","    examples = {}\n","    total = 0\n","\n","    with open(filename, \"r\") as fh:\n","        source = json.load(fh)\n","        total = len(source)\n","\n","    for idx in tqdm(range(total)):\n","        text = source[str(idx)][\"text\"]\n","        # basic text preprocessing\n","        text = text.replace(\"''\", '\" ').replace(\"``\", '\" ')  # replace the quotes \n","        text = text.replace(\"`\", \"'\") # backticks typo\n","        text = text.replace(\"\\\"\", \"\") # replace quotes\n","        text = text.replace(\"...\", \" \").replace(\". . .\", \" \").replace('..', ' ') # replace dots\n","        text = text.replace(\"\\n\", \" \") # replace new line chars\n","        text = re.sub(r'(?:http:|https:).*?(?=\\s)', '', text)  # remove url and website\n","        text = re.sub(r'www.*?(?=\\s)', '', text)  # remove url and website\n","\n","        list_to_replace = [':(', '=)', ':)', ':P', '-', ',,', ':', ';', '/', '+', '~', '_', '*', '(', ')', '&', '='] #replace the punctuations which are messy with empty\n","        for elem in list_to_replace:\n","            text = text.replace(elem, '')\n","        \n","        text = re.sub(r'\\!{2,}', '!', text) # duplicate punctuatio\n","        text = re.sub(r'\\?{2,}', '!', text) # duplicate punctuation\n","        text = text.replace('?!', '?').replace('!?', '?') #replace slang punctuation with question\n","        text = re.sub(r'\\s(?:\\.|\\,)', '', text) # replace spaces before punctuation\n","        text = re.sub(r'([a-zA-Z?!])\\1\\1+', r'\\1', text) # removes repeated characters (Ex: Veryyyyy -> very)\n","\n","        text = re.sub(r'\\s{2,}', ' ', text) # replace multiple spaces\n","        text = text.strip() # strips spaces\n","        text = text.lower() # lower text\n","\n","        examples[str(idx)] = {\"user_id\": source[str(idx)][\"user_id\"], \n","                              \"business_id\": source[str(idx)][\"business_id\"], \n","                              \"text\": text,\n","                              \"rating\": source[str(idx)][\"rating\"]}\n","\n","    return examples"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ml1ovCGFVyYk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1596291208598,"user_tz":240,"elapsed":22900,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"c4280ca0-1241-4ef2-ef88-fbd812b1c8c7"},"source":["train_examples = process_file('dataset/train.json', \"train\")\n","test_examples = process_file('dataset/test.json', \"test\")\n","test_examples_small = process_file('dataset/test_small.json', \"test\")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Pre-processing train examples...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 90000/90000 [00:11<00:00, 7651.18it/s]\n","  7%|▋         | 741/10000 [00:00<00:01, 7408.84it/s]"],"name":"stderr"},{"output_type":"stream","text":["Pre-processing test examples...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10000/10000 [00:01<00:00, 7834.07it/s]\n","100%|██████████| 100/100 [00:00<00:00, 6852.21it/s]"],"name":"stderr"},{"output_type":"stream","text":["Pre-processing test examples...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"skEuOH1wdFrG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["28f246f8847845cd80da00dfcff6ccce","06df6f88044b4cfbb558d6fa5aea4659","afa40917c1f04a87b91cd66e7e4b1bca","8082ce4c7b7a4081a7ddac0a87678203","28915ee20597455a9acc820a6f4cc872","cd26a6a9116c48c7aaa7ffc422752d5c","09fd72e30b234a3aa782958684f385d0","bad4a014333f478c9ff254caf98050a7"]},"executionInfo":{"status":"ok","timestamp":1596291208925,"user_tz":240,"elapsed":22690,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"a2c998ab-284f-4485-a3c3-c49474f57941"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28f246f8847845cd80da00dfcff6ccce","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V7Yzcj9mERX7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1596291208927,"user_tz":240,"elapsed":22089,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"850ae7d7-076e-4a1c-a823-1a13a8d781d0"},"source":["# Key Tokens\n","print('[CLS] token: ', tokenizer.convert_tokens_to_ids(\"[CLS]\"))\n","print('[SEP] token: ', tokenizer.convert_tokens_to_ids(\"[SEP]\"))\n","print('[PAD] token: ', tokenizer.convert_tokens_to_ids(\"[PAD]\"))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[CLS] token:  101\n","[SEP] token:  102\n","[PAD] token:  0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9-aOv4P4C6b7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291208928,"user_tz":240,"elapsed":21377,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def pad_sent(dataset, max_text_len = 350):  #token number 0 is [PAD]\n","    text = []\n","    attnmask = []\n","    seg_id = []\n","    rating = []\n","    uniq_ids = []\n","\n","    for idx in tqdm(dataset):\n","        uniq_ids.append(int(idx))  # append unique ids\n","        curr_text = dataset[str(idx)][\"text\"] # extract text\n","        curr_text = \"[CLS] \" + curr_text  # add starting cls token\n","        tokenized_text = tokenizer.tokenize(curr_text) # tokenize\n","        tokenized_ids = tokenizer.convert_tokens_to_ids(tokenized_text) # convert to ids\n","        \n","        tokenized_ids = tokenized_ids[:max_text_len - 1]   # trim the reviews\n","        tokenized_ids.append(102) # add special token for [SEP]\n","\n","        curr_sent_len = len(tokenized_ids)\n","        remaining = max_text_len - curr_sent_len # words remaining for padding\n","\n","        # pad the input token\n","        tokenized_ids.extend([0] * remaining)  # pad the text to max_text_len\n","        # add to storage\n","        text.append(tokenized_ids)\n","        \n","        # create attention and segmented mask\n","        curr_attn = [1] * curr_sent_len  \n","        curr_attn.extend([0] * remaining)\n","        curr_seg_id = [0] * max_text_len\n","\n","        # append to storage\n","        attnmask.append(curr_attn)\n","        seg_id.append(curr_seg_id)\n","        rating.append(dataset[str(idx)][\"rating\"])\n","\n","    return text, attnmask, seg_id, rating, uniq_ids"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3Ui0DOVDZtn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596291439208,"user_tz":240,"elapsed":251071,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"66d56d26-beca-4aaa-d554-fa5fb3e07540"},"source":["text, attnmask, seg_id, rating, uniq_ids = pad_sent(train_examples)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["100%|██████████| 90000/90000 [03:50<00:00, 391.01it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"OZ6LCImJJqVL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291454563,"user_tz":240,"elapsed":265924,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["np.savez('/content/gdrive/My Drive/Yelp_Sentiment_Analysis/train.npz',\n","         text = np.array(text),\n","         attnmask = np.array(attnmask),\n","         seg_id = np.array(seg_id),\n","         rating = np.array(rating),\n","         ids = np.array(uniq_ids)\n",")"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"CMjbL2u2C-cq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596291483141,"user_tz":240,"elapsed":294007,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"8a0bd43a-ba94-4729-e38b-57d0154a6075"},"source":["text, attnmask, seg_id, rating, uniq_ids = pad_sent(test_examples)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["100%|██████████| 10000/10000 [00:27<00:00, 360.44it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"j-U6qEmpJ1ro","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291484985,"user_tz":240,"elapsed":295274,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["np.savez('/content/gdrive/My Drive/Yelp_Sentiment_Analysis/test.npz',\n","         text = np.array(text),\n","         attnmask = np.array(attnmask),\n","         seg_id = np.array(seg_id),\n","         rating = np.array(rating),\n","         ids = np.array(uniq_ids)\n",")"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"vI9IsCZkJ7wo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596291485495,"user_tz":240,"elapsed":294969,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"e6039633-a232-4724-f983-0b8e70286cb0"},"source":["text, attnmask, seg_id, rating, uniq_ids = pad_sent(test_examples_small)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["100%|██████████| 100/100 [00:00<00:00, 345.24it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dCXjjejtH9HN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291485698,"user_tz":240,"elapsed":294748,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["np.savez('/content/gdrive/My Drive/Yelp_Sentiment_Analysis/test_small.npz',\n","         text = np.array(text),\n","         attnmask = np.array(attnmask),\n","         seg_id = np.array(seg_id),\n","         rating = np.array(rating),\n","         ids = np.array(uniq_ids)\n",")"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"kWEZNGgiH9dq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291485699,"user_tz":240,"elapsed":294107,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GcxOr_kEMIOo","colab_type":"text"},"source":["**Data Loader**"]},{"cell_type":"code","metadata":{"id":"cDLY7qpBMKOr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291485700,"user_tz":240,"elapsed":257268,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["import torch\n","import torch.utils.data as data\n","import numpy as np"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"VFpNW6K2MTaQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291485701,"user_tz":240,"elapsed":256762,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["class YelpDataset(data.Dataset):\n","    \"\"\"Yelp Dataset.\n","\n","    Each item in the dataset is a tuple with the following entries (in order):\n","         text = np.array(text),\n","         attnmask = np.array(attnmask),\n","         seg_id = np.array(seg_id),\n","         rating = np.array(rating),\n","         ids = np.array(uniq_ids)\n","\n","    Args:\n","        data_path (str): Path to .npz file containing pre-processed dataset.\n","    \"\"\"\n","    def __init__(self, data_path):\n","        super(YelpDataset, self).__init__()\n","\n","        dataset = np.load(data_path)\n","        self.text = torch.from_numpy(dataset['text']).long()\n","        self.attnmask = torch.from_numpy(dataset['attnmask']).long()\n","        self.seg_id = torch.from_numpy(dataset['seg_id']).long()\n","        self.rating = torch.from_numpy(dataset['rating']).long()\n","        self.ids = torch.from_numpy(dataset['ids']).long()\n","\n","        # index\n","        self.valid_idxs = [idx for idx in range(len(self.ids))]\n","\n","    def __getitem__(self, idx):\n","        idx = self.valid_idxs[idx]\n","        example = (self.text[idx],\n","                   self.attnmask[idx],\n","                   self.seg_id[idx],\n","                   self.rating[idx],\n","                   self.ids[idx])\n","        return example\n","\n","    def __len__(self):\n","        return len(self.valid_idxs)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMUZ9-EuMhCF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291488716,"user_tz":240,"elapsed":259116,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["train_dataset = YelpDataset('gdrive/My Drive/Yelp_Sentiment_Analysis/train.npz')\n","train_loader = data.DataLoader(train_dataset,\n","                                batch_size=8,\n","                                shuffle=True,\n","                                num_workers=4,\n","                                )\n","\n","dev_dataset = YelpDataset('gdrive/My Drive/Yelp_Sentiment_Analysis/test.npz')\n","dev_loader = data.DataLoader(dev_dataset,\n","                                batch_size=8,\n","                                shuffle=False,\n","                                num_workers=4,\n","                                )"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"uUv00L5iNnLe","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xlKJ2o-4N7SQ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nrz4qoi3p45G","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uJ31YSCZPKW3","colab_type":"text"},"source":["**BERT Finetune**"]},{"cell_type":"code","metadata":{"id":"iaWY4539PMnx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291493010,"user_tz":240,"elapsed":379,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","#import torch.optim.lr_scheduler as sched\n","from torch.optim.lr_scheduler import StepLR\n","\n","from transformers import BertTokenizer, BertModel, BertConfig\n","\n","\n","import numpy as np\n","import tqdm\n","from ujson import load as json_load\n","from collections import OrderedDict\n","from json import dumps\n","import random\n","import os\n","import logging\n","import queue\n","import shutil\n","import string\n","import re\n","\n","random.seed(224)\n","np.random.seed(224)\n","torch.manual_seed(224)\n","torch.cuda.manual_seed_all(224)\n","\n","from tensorboardX import SummaryWriter"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"tQ7QeZt3UVKN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291494956,"user_tz":240,"elapsed":839,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["class AverageMeter:\n","    \"\"\"Keep track of average values over time.\n","\n","    Adapted from:\n","        > https://github.com/pytorch/examples/blob/master/imagenet/main.py\n","    \"\"\"\n","    def __init__(self):\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def reset(self):\n","        \"\"\"Reset meter.\"\"\"\n","        self.__init__()\n","\n","    def update(self, val, num_samples=1):\n","        \"\"\"Update meter with new value `val`, the average of `num` samples.\n","\n","        Args:\n","            val (float): Average value to update the meter with.\n","            num_samples (int): Number of samples that were averaged to\n","                produce `val`.\n","        \"\"\"\n","        self.count += num_samples\n","        self.sum += val * num_samples\n","        self.avg = self.sum / self.count\n","\n","\n","class EMA:\n","    \"\"\"Exponential moving average of model parameters.\n","    Args:\n","        model (torch.nn.Module): Model with parameters whose EMA will be kept.\n","        decay (float): Decay rate for exponential moving average.\n","    \"\"\"\n","    def __init__(self, model, decay):\n","        self.decay = decay\n","        self.shadow = {}\n","        self.original = {}\n","\n","        # Register model parameters\n","        for name, param in model.named_parameters():\n","            if param.requires_grad:\n","                self.shadow[name] = param.data.clone()\n","\n","    def __call__(self, model, num_updates):\n","        decay = min(self.decay, (1.0 + num_updates) / (10.0 + num_updates))\n","        for name, param in model.named_parameters():\n","            if param.requires_grad:\n","                assert name in self.shadow\n","                new_average = \\\n","                    (1.0 - decay) * param.data + decay * self.shadow[name]\n","                self.shadow[name] = new_average.clone()\n","\n","    def assign(self, model):\n","        \"\"\"Assign exponential moving average of parameter values to the\n","        respective parameters.\n","        Args:\n","            model (torch.nn.Module): Model to assign parameter values.\n","        \"\"\"\n","        for name, param in model.named_parameters():\n","            if param.requires_grad:\n","                assert name in self.shadow\n","                self.original[name] = param.data.clone()\n","                param.data = self.shadow[name]\n","\n","    def resume(self, model):\n","        \"\"\"Restore original parameters to a model. That is, put back\n","        the values that were in each parameter at the last call to `assign`.\n","        Args:\n","            model (torch.nn.Module): Model to assign parameter values.\n","        \"\"\"\n","        for name, param in model.named_parameters():\n","            if param.requires_grad:\n","                assert name in self.shadow\n","                param.data = self.original[name]\n","\n","\n","class CheckpointSaver:\n","    \"\"\"Class to save and load model checkpoints.\n","\n","    Save the best checkpoints as measured by a metric value passed into the\n","    `save` method. Overwrite checkpoints with better checkpoints once\n","    `max_checkpoints` have been saved.\n","\n","    Args:\n","        save_dir (str): Directory to save checkpoints.\n","        max_checkpoints (int): Maximum number of checkpoints to keep before\n","            overwriting old ones.\n","        metric_name (str): Name of metric used to determine best model.\n","        maximize_metric (bool): If true, best checkpoint is that which maximizes\n","            the metric value passed in via `save`. Otherwise, best checkpoint\n","            minimizes the metric.\n","        log (logging.Logger): Optional logger for printing information.\n","    \"\"\"\n","    def __init__(self, save_dir, max_checkpoints, metric_name,\n","                 maximize_metric=False, log=None):\n","        super(CheckpointSaver, self).__init__()\n","\n","        self.save_dir = save_dir\n","        self.max_checkpoints = max_checkpoints\n","        self.metric_name = metric_name\n","        self.maximize_metric = maximize_metric\n","        self.best_val = None\n","        self.ckpt_paths = queue.PriorityQueue()\n","        self.log = log\n","        self._print(f\"Saver will {'max' if maximize_metric else 'min'}imize {metric_name}...\")\n","\n","    def is_best(self, metric_val):\n","        \"\"\"Check whether `metric_val` is the best seen so far.\n","\n","        Args:\n","            metric_val (float): Metric value to compare to prior checkpoints.\n","        \"\"\"\n","        if metric_val is None:\n","            # No metric reported\n","            return False\n","\n","        if self.best_val is None:\n","            # No checkpoint saved yet\n","            return True\n","\n","        return ((self.maximize_metric and self.best_val < metric_val)\n","                or (not self.maximize_metric and self.best_val > metric_val))\n","\n","    def _print(self, message):\n","        \"\"\"Print a message if logging is enabled.\"\"\"\n","        if self.log is not None:\n","            self.log.info(message)\n","\n","    def save(self, step, model, metric_val, device):\n","        \"\"\"Save model parameters to disk.\n","\n","        Args:\n","            step (int): Total number of examples seen during training so far.\n","            model (torch.nn.DataParallel): Model to save.\n","            metric_val (float): Determines whether checkpoint is best so far.\n","            device (torch.device): Device where model resides.\n","        \"\"\"\n","        ckpt_dict = {\n","            'model_name': model.__class__.__name__,\n","            'model_state': model.cpu().state_dict(),\n","            'step': step\n","        }\n","        model.to(device)\n","\n","        checkpoint_path = os.path.join(self.save_dir,\n","                                       f'step_{step}.pth.tar')\n","        torch.save(ckpt_dict, checkpoint_path)\n","        self._print(f'Saved checkpoint: {checkpoint_path}')\n","\n","        if self.is_best(metric_val):\n","            # Save the best model\n","            self.best_val = metric_val\n","            best_path = os.path.join(self.save_dir, 'best.pth.tar')\n","            shutil.copy(checkpoint_path, best_path)\n","            self._print(f'New best checkpoint at step {step}...')\n","\n","        # Add checkpoint path to priority queue (lowest priority removed first)\n","        if self.maximize_metric:\n","            priority_order = metric_val\n","        else:\n","            priority_order = -metric_val\n","\n","        self.ckpt_paths.put((priority_order, checkpoint_path))\n","\n","        # Remove a checkpoint if more than max_checkpoints have been saved\n","        if self.ckpt_paths.qsize() > self.max_checkpoints:\n","            _, worst_ckpt = self.ckpt_paths.get()\n","            try:\n","                os.remove(worst_ckpt)\n","                self._print(f'Removed checkpoint: {worst_ckpt}')\n","            except OSError:\n","                # Avoid crashing if checkpoint has been removed or protected\n","                pass\n","\n","def load_model(model, checkpoint_path, gpu_ids, return_step=True):\n","    \"\"\"Load model parameters from disk.\n","\n","    Args:\n","        model (torch.nn.DataParallel): Load parameters into this model.\n","        checkpoint_path (str): Path to checkpoint to load.\n","        gpu_ids (list): GPU IDs for DataParallel.\n","        return_step (bool): Also return the step at which checkpoint was saved.\n","\n","    Returns:\n","        model (torch.nn.DataParallel): Model loaded from checkpoint.\n","        step (int): Step at which checkpoint was saved. Only if `return_step`.\n","    \"\"\"\n","    device = f\"cuda:{gpu_ids[0] if gpu_ids else 'cpu'}\"\n","    ckpt_dict = torch.load(checkpoint_path, map_location=device)\n","\n","    # Build model, load parameters\n","    model.load_state_dict(ckpt_dict['model_state'])\n","\n","    if return_step:\n","        step = ckpt_dict['step']\n","        return model, step\n","\n","    return model\n","\n","def get_logger(log_dir, name):\n","    \"\"\"Get a `logging.Logger` instance that prints to the console\n","    and an auxiliary file.\n","\n","    Args:\n","        log_dir (str): Directory in which to create the log file.\n","        name (str): Name to identify the logs.\n","\n","    Returns:\n","        logger (logging.Logger): Logger instance for logging events.\n","    \"\"\"\n","    class StreamHandlerWithTQDM(logging.Handler):\n","        \"\"\"Let `logging` print without breaking `tqdm` progress bars.\n","\n","        See Also:\n","            > https://stackoverflow.com/questions/38543506\n","        \"\"\"\n","        def emit(self, record):\n","            try:\n","                msg = self.format(record)\n","                tqdm.tqdm.write(msg)\n","                self.flush()\n","            except (KeyboardInterrupt, SystemExit):\n","                raise\n","            except:\n","                self.handleError(record)\n","\n","    # Create logger\n","    logger = logging.getLogger(name)\n","    logger.setLevel(logging.DEBUG)\n","\n","    # Log everything (i.e., DEBUG level and above) to a file\n","    log_path = os.path.join(log_dir, 'log.txt')\n","    file_handler = logging.FileHandler(log_path)\n","    file_handler.setLevel(logging.DEBUG)\n","\n","    # Log everything except DEBUG level (i.e., INFO level and above) to console\n","    console_handler = StreamHandlerWithTQDM()\n","    console_handler.setLevel(logging.INFO)\n","\n","    # Create format for the logs\n","    file_formatter = logging.Formatter('[%(asctime)s] %(message)s',\n","                                       datefmt='%m.%d.%y %H:%M:%S')\n","    file_handler.setFormatter(file_formatter)\n","    console_formatter = logging.Formatter('[%(asctime)s] %(message)s',\n","                                          datefmt='%m.%d.%y %H:%M:%S')\n","    console_handler.setFormatter(console_formatter)\n","\n","    # add the handlers to the logger\n","    logger.addHandler(file_handler)\n","    logger.addHandler(console_handler)\n","\n","    return logger"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"55BHaZHcb9f2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291496290,"user_tz":240,"elapsed":333,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDaKMqfRPOea","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291497141,"user_tz":240,"elapsed":334,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["class BertFineTune(nn.Module):\n","    def __init__(self):\n","        super(BertFineTune, self).__init__()\n","        self.embed_model = BertModel.from_pretrained('bert-base-uncased')\n","        self.fc_weight = nn.Parameter(torch.zeros(768, 5), requires_grad = True)  # 5 represents the number of classes \n","        self.fc_bias = nn.Parameter(torch.zeros(1,5), requires_grad = True)\n","        nn.init.xavier_uniform_(self.fc_weight)  # FC layer initialization\n","        self.softmax_layer = nn.LogSoftmax(dim = 1)  # uses logsoftmax for NLL loss instead of normal softmax\n","\n","    def forward(self, x, seg_id_tensor, attnmask_tensor):\n","        original = torch.zeros([x.size()[0], 350, 768], dtype = torch.float32, device = 'cuda:0') #, device=device) # batchsize x max_text_len x hidden_size\n","        mask = torch.ones([x.size()[0], 350], dtype = torch.float32, device = 'cuda:0') #, device=device)  # batchsize x max_text_len\n","        sep_idxs = (x == 102).nonzero().reshape(x.size()[0], -1)  # [idx, pos of [SEP] token]\n","\n","        for i in range(x.size()[0]):\n","            # get pre-contextual word embedding from BERT\n","            curr_embed = torch.zeros([1,350,768], dtype=torch.float32)\n","            # take the BERT embedding\n","            # last_hidden_states = last_layer_embedding  (batch_size, seq_len, hidden_size)\n","            # pooler output = last_layer_embedding further preprocessed by linear and Tanh layers\n","            # hidden_states = tuple of length 13 (one for output of embedding layer and 12 output for each layer in the transformer)  \n","            last_hidden_states, pooler_output, hidden_states = self.embed_model(x[i:i+1], token_type_ids = seg_id_tensor[i:i+1], \n","                                                                                attention_mask = attnmask_tensor[i:i+1], \n","                                                                                output_hidden_states = True) \n","            \n","            # do masking and filter pad sequences\n","            # set embedding after the [SEP] token to 0, and also create the masking\n","            curr_embed = last_hidden_states\n","            end_text = sep_idxs[i,1].item()\n","            curr_embed[0,end_text+1:,:] = torch.zeros([350 - (end_text+1), 768], dtype = torch.float32)  # set everything else to 0 after [SEP] token\n","            mask[i,end_text+1:] = torch.zeros([350 - (end_text+1)], dtype=torch.float32)  # set everything else to 0 after [SEP] token\n","            original[i] = curr_embed\n","\n","        # Take [CLS] token embedding which is at index 0\n","        cls_embed = original[:,0,:]  # size = batch_size x 768\n","\n","        # attach FC layer after the CLS word embeddings\n","        dotted = torch.matmul(cls_embed, self.fc_weight) # size = batch_size x 5, 5 = Number of classes\n","        dotted = dotted.add(self.fc_bias) # add the bias  (batch_size x 5)\n","\n","        # perform log softmax to normalize\n","        softmax_output = self.softmax_layer(dotted)\n","\n","        return softmax_output"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zx0yvG54dnzF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291498393,"user_tz":240,"elapsed":383,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"dr7_t3bbkOXZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291499250,"user_tz":240,"elapsed":309,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def get_prediction(review_ids, log_softmax_score):\n","    \"\"\"\n","    review_ids (int): Tensor of Review example IDs.\n","    log_softmax_score (list): tensor of log likehood scores (take max to get prediction)\n","    \"\"\"\n","    maxs = torch.argmax(log_softmax_score, dim = 1)\n","\n","    pred_dict = {}\n","    for id, max_val in zip(review_ids, maxs):\n","        pred_dict[id.item()] = max_val.item() \n","    return pred_dict"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"udGNPzYsnb55","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291500159,"user_tz":240,"elapsed":296,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def evaluate_dict(gold_dict, pred_dict):\n","    sum_acc = 0\n","    total = 0\n","    \n","    for key, value in pred_dict.items():\n","        total += 1\n","        ground_truths = gold_dict[key]\n","        prediction = value\n","        if ground_truths == prediction:\n","            sum_acc += 1\n","\n","    eval_dict = {'acc': 100. * sum_acc / total}\n","\n","    return eval_dict"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"oWTL2JKAckzE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291500997,"user_tz":240,"elapsed":326,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def evaluate(model, data_loader, eval_file, device):\n","    nll_meter = AverageMeter()\n","\n","    model.eval()\n","    pred_dict = {}\n","\n","    # get all true labels for ratings\n","    test_dataset = np.load(eval_file)\n","    true_labels = torch.from_numpy(test_dataset['rating']).long()\n","    uniq_ids = torch.from_numpy(test_dataset['ids']).long()\n","    true_labels = true_labels - 1 ## Need to subtract 1 because classes need to be 0 to n_classes - 1\n","    gold_dict = {}\n","    for true, ids in zip(true_labels, uniq_ids):\n","        gold_dict[ids.item()] = true.item()\n","\n","    with torch.no_grad(), tqdm.notebook.tqdm(total=len(data_loader.dataset), position=1, leave=True) as progress_bar:\n","        for text, attnmask, seg_id, rating, ids  in data_loader:\n","            # Setup for forward\n","            text = text.to(device)\n","            attnmask = attnmask.to(device)\n","            seg_id = seg_id.to(device)\n","            batch_size = text.size(0)\n","            ids = ids.to(device)\n","\n","            # Forward\n","            log_softmax_scores = model(text, seg_id, attnmask)\n","            rating = rating.to(device)\n","            # rating needs to be 0 to num_classes - 1\n","            rating = rating - 1\n","\n","            loss = F.nll_loss(log_softmax_scores, rating)\n","            nll_meter.update(loss.item(), batch_size)\n","\n","            # Get maximum prediction for prediction\n","            preds = get_prediction(ids, log_softmax_score)\n","            pred_dict.update(preds)\n","\n","            # Log info\n","            progress_bar.update(batch_size)\n","            progress_bar.set_postfix(NLL=nll_meter.avg)\n","\n","    model.train()\n","\n","    results = evaluate_dict(gold_dict, pred_dict)\n","    results_list = [('NLL', nll_meter.avg),\n","                    ('acc', results['acc'])]\n","\n","    results = OrderedDict(results_list)\n","    return results, pred_dict"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"7NmBfMajxS9_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596291502039,"user_tz":240,"elapsed":448,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def visualize(tbx, pred_dict, eval_path, step, split, num_visuals):\n","    \"\"\"Visualize text examples to TensorBoard.\n","\n","    Args:\n","        tbx (tensorboardX.SummaryWriter): Summary writer.\n","        pred_dict (dict): dict of predictions of the form id -> pred.\n","        eval_path (str): Path to eval JSON file.\n","        step (int): Number of examples seen so far during training.\n","        split (str): Name of data split being visualized.\n","        num_visuals (int): Number of visuals to select at random from preds.\n","    \"\"\"\n","    if num_visuals <= 0:\n","        return\n","    if num_visuals > len(pred_dict):\n","        num_visuals = len(pred_dict)\n","\n","    visual_ids = np.random.choice(list(pred_dict), size=num_visuals, replace=False)\n","\n","    with open(eval_path, 'r') as eval_file:\n","        eval_dict = json.load(eval_file)\n","    for i, id_ in enumerate(visual_ids):\n","        pred = pred_dict[id_] + 1 # NEED POST PROCESSING BECAUSE WE SUBTRACTED TO COMPLY WITH NLL LOSS LABELS (0, n_classes - 1)\n","        example = eval_dict[str(id_)]\n","        user_id = example['user_id']\n","        business_id = example['business_id']\n","        text = example['text']\n","        gold = int(example['rating'])\n","\n","        tbl_fmt = (f'- **Reviews:** {text}\\n'\n","                   + f'- **Answer:** {gold}\\n'\n","                   + f'- **Prediction:** {pred}')\n","        tbx.add_text(tag=f'{split}/{i+1}_of_{num_visuals}',\n","                     text_string=tbl_fmt,\n","                     global_step=step)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iahdbuh1REbj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["aaf4f27ffa0d46b595cea779853f7e19","c3a8348a1d6040b89055f15f841a1919","ba655ea92ca34aca9c3c7f261f9d692d","4859fc421dfe4626b28e508886558a2e","5bd5e898c14446d48cca0b79ccca019e","77ce6c600c7c4c47804580c6cd88b402","00bb7913867049d2b30b8c4528733c54","849690a463f944e38279cf66a8e17fa9","a4651ed07c8c498ab05eb9c772bede82","83844f0e5e204353a67e61d5767d5147","419563b0b43f40cbaca264873dea672e","0b4e9a74470c44f0b56b5c2d84abe2f8","afdbf58b0c7943aa871dbe898761590e","69726cec0dcc4c9fa546df2b5d924d93","ad2ead213bfb4330bd344248af798cea","1712fec3b5df4621ab47de098022a095"]},"executionInfo":{"status":"ok","timestamp":1596291530317,"user_tz":240,"elapsed":27771,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"bf38b000-7bcb-495b-f3c5-e1c7f0387224"},"source":["save_dir = 'gdrive/My Drive/Yelp_Sentiment_Analysis/save/train/baseline-01'\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","\n","log = get_logger(save_dir, 'baseline')\n","tbx = SummaryWriter(save_dir)\n","log.info(f'Using random seed 224 ...')\n","\n","saver = CheckpointSaver(save_dir,\n","                        max_checkpoints=5,\n","                        metric_name='acc',\n","                        maximize_metric='acc',\n","                        log=log)\n","\n","model = BertFineTune()\n","model = model.to('cuda:0')\n","model.train()\n","optimizer = optim.Adam(model.parameters(), lr = 0.00005)\n","#scheduler = sched.LambdaLR(optimizer, lambda s: 1.)  # Constant LR\n","\n","# LEARNING RATE SCHEDULER\n","# step_size: at how many multiples of epoch you decay\n","# step_size = 1, after every 1 epoch, new_lr = lr*gamma \n","# step_size = 2, after every 2 epoch, new_lr = lr*gamma \n","# gamma = decaying factor\n","#scheduler = StepLR(optimizer, step_size=1, gamma=0.9)\n","\n","\n","ema = EMA(model, 0.999)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["[08.01.20 14:18:23] Using random seed 224 ...\n","[08.01.20 14:18:23] Saver will maximize acc...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aaf4f27ffa0d46b595cea779853f7e19","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4651ed07c8c498ab05eb9c772bede82","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sshT32C6SZbZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":190,"referenced_widgets":["a278dea474e5430a9f0df438522155ac","98011c1395434013ad83377d8e4e85b2","2a6ae962ab3545e99f2877f7aa404c22","fa7256265f1b41f699d9ef01459ac09b","86ed618eaed44ab0addc07a9f26c23a9","f48c90eebc304d5c81618f7d45398a4a","77360e69cbff4423b9e4b5ffbac729b4","396702d2aae34ed69334ab4c1ca575f3","8c56834132a140d7bed8c3b376962f5e","53f2dfe5c935476abcdb0ddc33dbc09f","3b309a4776874502a65f365c75867264","42943c336b1f47b5a92d3a5f0b5478eb"]},"outputId":"ddda40c0-e982-40e4-e790-c5f848418966"},"source":["epoch = 0\n","step = 0\n","steps_till_eval = 30000 # evaluate model after 30000 iterations\n","device = 'cuda:0'\n","while epoch != 3:  # Num Epochs to train on \n","    epoch += 1\n","    #scheduler.step()     # Decay Learning Rate\n","    log.info(f'Starting epoch {epoch}...')\n","    with torch.enable_grad(), tqdm.tqdm(total=len(train_loader.dataset), position=0, leave=True) as progress_bar:\n","        for text, attnmask, seg_id, rating, ids in train_loader:\n","            # Setup for forward\n","            text = text.to(device)\n","            attnmask = attnmask.to(device)\n","            seg_id = seg_id.to(device)\n","            batch_size = text.size(0)\n","            optimizer.zero_grad()\n","\n","            # Forward\n","            log_softmax_score = model(text, seg_id, attnmask)\n","            rating = rating.to(device)\n","            \n","            # need ratings to be 0 to n_classes - 1 (can later transform it)\n","            rating = rating - 1\n","            \n","            loss = F.nll_loss(log_softmax_score, rating)  #NLL loss for correct position\n","            loss_val = loss.item()\n","\n","            # Backward\n","            loss.backward()\n","            nn.utils.clip_grad_norm_(model.parameters(), 3)  # clip max gradients to 3\n","            optimizer.step()\n","            ema(model, step // batch_size)\n","\n","            # Log info\n","            step += batch_size\n","            progress_bar.update(batch_size)\n","            progress_bar.set_postfix(epoch=epoch, NLL=loss_val)\n","            \n","            tbx.add_scalar('train/NLL', loss_val, step)\n","            tbx.add_scalar('train/LR',\n","                             optimizer.param_groups[0]['lr'],\n","                             step)\n","            \n","            steps_till_eval -= batch_size\n","            if steps_till_eval <= 0:\n","                steps_till_eval = 30000\n","\n","                # Evaluate and save checkpoint\n","                log.info(f'Evaluating at step {step}...')\n","                ema.assign(model)\n","                results, pred_dict = evaluate(model, dev_loader, 'gdrive/My Drive/Yelp_Sentiment_Analysis/test.npz', device)\n","                \n","                saver.save(step, model, results['acc'], device)\n","                ema.resume(model)\n","\n","                # Log to console\n","                results_str = ', '.join(f'{k}: {v:05.2f}' for k, v in results.items())\n","                log.info(f'Dev {results_str}')\n","\n","                # Log to TensorBoard\n","                log.info('Visualizing in TensorBoard...')\n","                for k, v in results.items():\n","                     tbx.add_scalar(f'dev/{k}', v, step)\n","\n","                visualize(tbx,\n","                          pred_dict=pred_dict,\n","                          eval_path='dataset/test.json',\n","                          step=step,\n","                          split='dev',\n","                          num_visuals=30)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","\r  0%|          | 0/90000 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[08.01.20 14:18:50] Starting epoch 1...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n","  del sys.path[0]\n"," 33%|███▎      | 30000/90000 [29:24<59:10, 16.90it/s, NLL=0.759, epoch=1]"],"name":"stderr"},{"output_type":"stream","text":["[08.01.20 14:48:14] Evaluating at step 30000...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a278dea474e5430a9f0df438522155ac","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r 33%|███▎      | 30000/90000 [29:34<59:10, 16.90it/s, NLL=0.759, epoch=1]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 30000/90000 [32:30<59:10, 16.90it/s, NLL=0.759, epoch=1]"],"name":"stderr"},{"output_type":"stream","text":["[08.01.20 14:51:21] Saved checkpoint: gdrive/My Drive/Yelp_Sentiment_Analysis/save/train/baseline-01/step_30000.pth.tar\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 30000/90000 [32:33<59:10, 16.90it/s, NLL=0.759, epoch=1]"],"name":"stderr"},{"output_type":"stream","text":["[08.01.20 14:51:24] New best checkpoint at step 30000...\n","[08.01.20 14:51:24] Dev NLL: 00.83, acc: 19.34\n","[08.01.20 14:51:24] Visualizing in TensorBoard...\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 60000/90000 [1:01:58<29:34, 16.90it/s, NLL=1.06, epoch=1]"],"name":"stderr"},{"output_type":"stream","text":["[08.01.20 15:20:48] Evaluating at step 60000...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c56834132a140d7bed8c3b376962f5e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r 67%|██████▋   | 60000/90000 [1:02:10<29:34, 16.90it/s, NLL=1.06, epoch=1]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 60000/90000 [1:05:00<29:34, 16.90it/s, NLL=1.06, epoch=1]"],"name":"stderr"},{"output_type":"stream","text":["[08.01.20 15:23:51] Saved checkpoint: gdrive/My Drive/Yelp_Sentiment_Analysis/save/train/baseline-01/step_60000.pth.tar\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 60000/90000 [1:05:03<29:34, 16.90it/s, NLL=1.06, epoch=1]"],"name":"stderr"},{"output_type":"stream","text":["[08.01.20 15:23:54] New best checkpoint at step 60000...\n","[08.01.20 15:23:54] Dev NLL: 00.81, acc: 20.19\n","[08.01.20 15:23:54] Visualizing in TensorBoard...\n"],"name":"stdout"},{"output_type":"stream","text":[" 99%|█████████▉| 89064/90000 [1:33:37<00:54, 17.07it/s, NLL=1.13, epoch=1] "],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"MTbVaDOUsVnl","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o0Q9Qvt0GRvS","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FpKHTit6sV9W","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aT0GDfwJsV3k","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Pge2PniUByw","colab_type":"code","colab":{}},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","\n","inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n","outputs = model(**inputs, output_hidden_states = True)\n","\n","last_hidden_states, pooler_output, hidden_states = outputs  # The last hidden-state is the first element of the output tuple"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z96u1ehInj3A","colab_type":"code","colab":{}},"source":["inputs['input_ids'].size()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hduiWE3WjgqJ","colab_type":"code","colab":{}},"source":["last_hidden_states.size()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xr9AQ--hnPVi","colab_type":"code","colab":{}},"source":["hidden_states"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sN1KGDkenIpG","colab_type":"code","colab":{}},"source":["hidden_states[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WEGMjamWlHII","colab_type":"code","colab":{}},"source":["len(hidden_states)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1SWF0UwAmhvW","colab_type":"code","colab":{}},"source":["last_hidden_states.size()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4_rWZz8vmcT7","colab_type":"code","colab":{}},"source":["hidden_states[].size()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K7Hy4nZSjpr4","colab_type":"code","colab":{}},"source":["model.config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g04jgxZnj8Yg","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_vbrQecloMk","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hY_FoxSflrcq","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}