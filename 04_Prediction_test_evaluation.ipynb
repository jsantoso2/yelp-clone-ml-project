{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04_Prediction.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMbJpBe5w/9LXv/z2GwfJv/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c54b49bc30064aa99032dfb4a86d30d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b8820a7d8b704fc0aa4769602793dd88","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a2ad5c9076b04da1a89e75ae8b3ab4da","IPY_MODEL_cacc1121b30b4d63a293c1f72f18c8f1"]}},"b8820a7d8b704fc0aa4769602793dd88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2ad5c9076b04da1a89e75ae8b3ab4da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fd19d57047d24e1f886cdb7bf081cfd4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_74d82dd69b194294a6bfd54fa9fcef0d"}},"cacc1121b30b4d63a293c1f72f18c8f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bc6ff322c55c4487b625b648592108f7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 1.54MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5cdddc4448b24ad796733472c932325b"}},"fd19d57047d24e1f886cdb7bf081cfd4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"74d82dd69b194294a6bfd54fa9fcef0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc6ff322c55c4487b625b648592108f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5cdddc4448b24ad796733472c932325b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19e3b3199ac449438b573d6604cc57ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_64a6c643ce60426e9341f1466f59ae97","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dc1e5cb0ca074c96aeb21edb82982be6","IPY_MODEL_07faa577926a413f825de764bb6cb9b2"]}},"64a6c643ce60426e9341f1466f59ae97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dc1e5cb0ca074c96aeb21edb82982be6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5e8cf5476b16415683b7e8d8cf8b7a1c","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b42bc532fd754db19ce4f644f87d3d5b"}},"07faa577926a413f825de764bb6cb9b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6278828bba1841b2838bc943f609fd0d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10000/10000 [06:56&lt;00:00, 24.01it/s, NLL=0.776]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b63ecf34c36b456cafcfdcbddfc72b4b"}},"5e8cf5476b16415683b7e8d8cf8b7a1c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b42bc532fd754db19ce4f644f87d3d5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6278828bba1841b2838bc943f609fd0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b63ecf34c36b456cafcfdcbddfc72b4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"7nWHsofSQcVx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1596559493129,"user_tz":240,"elapsed":1095,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"1d42c0b7-988b-4cc1-e0a9-6efa352a31e9"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Aug  4 16:44:53 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ey9EoCyDRClP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":595},"executionInfo":{"status":"ok","timestamp":1596559501229,"user_tz":240,"elapsed":9152,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"8904da59-1eb3-4139-e27b-916d7025ea85"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 16.2MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 28.0MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 35.3MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=4b11fd54c833cf49cc7ffa2ac96d9ae7977ed8d9bfc17004dc5299a55f023387\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mQEHRwhMXcEE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1596559579946,"user_tz":240,"elapsed":4023,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"3cd7fd98-378e-49a5-934e-a11551d949d5"},"source":["!pip install tensorboardX"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Collecting tensorboardX\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n","\r\u001b[K     |█                               | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 256kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 276kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 296kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 307kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 3.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (49.2.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DVULomjaRIOR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1596559532105,"user_tz":240,"elapsed":33401,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"10f5b0c5-aac7-420f-fc12-5a6f5f500369"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RXScLCjxSDTl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596561081493,"user_tz":240,"elapsed":2930,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["!unzip -q \"/content/gdrive/My Drive/Yelp_Sentiment_Analysis/dataset.zip\" -d '/content'"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"opnBZ86WaEOu","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zAjgAQAtUKYd","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"cO43wP4yExre","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MiNJrKdrEy1G","colab_type":"text"},"source":["**Prediction**"]},{"cell_type":"code","metadata":{"id":"-GpOpjbJEx3a","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559540772,"user_tz":240,"elapsed":6367,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["import torch\n","from transformers import BertTokenizer, BertModel\n","\n","import re\n","import numpy as np"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"MRy6M3TvEyCA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["c54b49bc30064aa99032dfb4a86d30d2","b8820a7d8b704fc0aa4769602793dd88","a2ad5c9076b04da1a89e75ae8b3ab4da","cacc1121b30b4d63a293c1f72f18c8f1","fd19d57047d24e1f886cdb7bf081cfd4","74d82dd69b194294a6bfd54fa9fcef0d","bc6ff322c55c4487b625b648592108f7","5cdddc4448b24ad796733472c932325b"]},"executionInfo":{"status":"ok","timestamp":1596559541246,"user_tz":240,"elapsed":5698,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"62edb212-7fcf-41ab-9899-29bb7fa506ac"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c54b49bc30064aa99032dfb4a86d30d2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5aVPVlxZIywE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1596559541247,"user_tz":240,"elapsed":4984,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"cb26deec-b914-4f2a-fba3-ce4a5600da5e"},"source":["# Key Tokens\n","print('[CLS] token: ', tokenizer.convert_tokens_to_ids(\"[CLS]\"))\n","print('[SEP] token: ', tokenizer.convert_tokens_to_ids(\"[SEP]\"))\n","print('[PAD] token: ', tokenizer.convert_tokens_to_ids(\"[PAD]\"))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[CLS] token:  101\n","[SEP] token:  102\n","[PAD] token:  0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mqF_EyqPFbtK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559541248,"user_tz":240,"elapsed":4242,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def clean_text(text):\n","    # basic text preprocessing\n","    text = text.replace(\"''\", '\" ').replace(\"``\", '\" ')  # replace the quotes \n","    text = text.replace(\"`\", \"'\") # backticks typo\n","    text = text.replace(\"\\\"\", \"\") # replace quotes\n","    text = text.replace(\"...\", \" \").replace(\". . .\", \" \").replace('..', ' ') # replace dots\n","    text = text.replace(\"\\n\", \" \") # replace new line chars\n","    text = re.sub(r'(?:http:|https:).*?(?=\\s)', '', text)  # remove url and website\n","    text = re.sub(r'www.*?(?=\\s)', '', text)  # remove url and website\n","\n","    list_to_replace = [':(', '=)', ':)', ':P', '-', ',,', ':', ';', '/', '+', '~', '_', '*', '(', ')', '&', '=', '@'] #replace the punctuations which are messy with empty\n","    for elem in list_to_replace:\n","        text = text.replace(elem, '')\n","    \n","    text = re.sub(r'\\!{2,}', '!', text) # duplicate punctuation\n","    text = re.sub(r'\\?{2,}', '?', text) # duplicate punctuation\n","    text = text.replace('?!', '?').replace('!?', '?') #replace slang punctuation with question\n","    text = re.sub(r'\\s(?:\\.|\\,)', '', text) # replace spaces before punctuation\n","    text = re.sub(r'([a-zA-Z?!])\\1\\1+', r'\\1', text) # removes repeated characters (Ex: Veryyyyy -> very)\n","    \n","    text = re.sub(r'\\s{2,}', ' ', text) # replace multiple spaces\n","    text = text.strip() # strips spaces\n","\n","    text = text.lower() # lower text\n","\n","    return text"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"fD2z1y9WI7gs","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559541249,"user_tz":240,"elapsed":3661,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def pad_sent(raw_text, max_text_len = 350):  #token number 0 is [PAD]\n","    curr_text = \"[CLS] \" + raw_text  # add starting cls token\n","    tokenized_text = tokenizer.tokenize(curr_text) # tokenize            \n","    tokenized_ids = tokenizer.convert_tokens_to_ids(tokenized_text) # convert to ids\n","\n","    tokenized_ids = tokenized_ids[:max_text_len - 1]   # trim the reviews\n","    tokenized_ids.append(102) # add special token for [SEP]\n","    \n","    # get text length and padding\n","    curr_sent_len = len(tokenized_ids)\n","    remaining = max_text_len - curr_sent_len # words remaining for padding\n","\n","    # pad the input token\n","    tokenized_ids.extend([0] * remaining)  # pad the text to max_text_len\n","\n","    # create attention and segmented mask\n","    curr_attn = [1] * curr_sent_len  \n","    curr_attn.extend([0] * remaining)\n","    curr_seg_id = [0] * max_text_len\n","\n","    return tokenized_ids, curr_attn, curr_seg_id"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"nMYUl43rFb4g","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559541250,"user_tz":240,"elapsed":3107,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["test_string = 'I hate this FOOD!!!'\n","test_string = clean_text(test_string)\n","tokenized_ids, curr_attn, curr_seg_id = pad_sent(test_string)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mt5R90j_SUd-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559541251,"user_tz":240,"elapsed":2599,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fid_Ze71NGrk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559541252,"user_tz":240,"elapsed":2150,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"nIlpy8OfTJ9X","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559541252,"user_tz":240,"elapsed":1865,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"IcH_8z6QTKLc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559541253,"user_tz":240,"elapsed":1378,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZFjB6JxYTKhZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559541254,"user_tz":240,"elapsed":1107,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"MBDjtIuwTKrL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559541255,"user_tz":240,"elapsed":679,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GcxOr_kEMIOo","colab_type":"text"},"source":["**Data Loader**"]},{"cell_type":"code","metadata":{"id":"cDLY7qpBMKOr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559541863,"user_tz":240,"elapsed":297,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["import torch\n","import torch.utils.data as data\n","import numpy as np"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"VFpNW6K2MTaQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559542305,"user_tz":240,"elapsed":221,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["class YelpDataset(data.Dataset):\n","    \"\"\"Yelp Dataset.\n","\n","    Each item in the dataset is a tuple with the following entries (in order):\n","         text = np.array(text),\n","         attnmask = np.array(attnmask),\n","         seg_id = np.array(seg_id),\n","         rating = np.array(rating),\n","         ids = np.array(uniq_ids)\n","\n","    Args:\n","        data_path (str): Path to .npz file containing pre-processed dataset.\n","    \"\"\"\n","    def __init__(self, data_path):\n","        super(YelpDataset, self).__init__()\n","\n","        dataset = np.load(data_path)\n","        self.text = torch.from_numpy(dataset['text']).long()\n","        self.attnmask = torch.from_numpy(dataset['attnmask']).long()\n","        self.seg_id = torch.from_numpy(dataset['seg_id']).long()\n","        self.rating = torch.from_numpy(dataset['rating']).long()\n","        self.ids = torch.from_numpy(dataset['ids']).long()\n","\n","        # index\n","        self.valid_idxs = [idx for idx in range(len(self.ids))]\n","\n","    def __getitem__(self, idx):\n","        idx = self.valid_idxs[idx]\n","        example = (self.text[idx],\n","                   self.attnmask[idx],\n","                   self.seg_id[idx],\n","                   self.rating[idx],\n","                   self.ids[idx])\n","        return example\n","\n","    def __len__(self):\n","        return len(self.valid_idxs)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMUZ9-EuMhCF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559544036,"user_tz":240,"elapsed":1576,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["dev_dataset = YelpDataset('gdrive/My Drive/Yelp_Sentiment_Analysis/test.npz')\n","dev_loader = data.DataLoader(dev_dataset,\n","                                batch_size=16,\n","                                shuffle=False,\n","                                num_workers=4,\n","                                )"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"5dHkbQABUDgM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559544038,"user_tz":240,"elapsed":1172,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"H16_RnMtUDt5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559544039,"user_tz":240,"elapsed":667,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7tfRDLxZUisj","colab_type":"text"},"source":["**BERT FINETUNE**"]},{"cell_type":"code","metadata":{"id":"ZjZal-BhUD6Y","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559585464,"user_tz":240,"elapsed":301,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","from torch.optim.lr_scheduler import StepLR\n","from transformers import BertTokenizer, BertModel, BertConfig\n","\n","import numpy as np\n","import tqdm\n","#from ujson import load as json_load\n","from collections import OrderedDict\n","from json import dumps\n","import random\n","import os\n","import logging\n","import queue\n","import shutil\n","import string\n","import re\n","import json\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import recall_score\n","\n","random.seed(224)\n","np.random.seed(224)\n","torch.manual_seed(224)\n","torch.cuda.manual_seed_all(224)\n","\n","from tensorboardX import SummaryWriter"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"wY-7ZH-oUEGx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559588891,"user_tz":240,"elapsed":264,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["class AverageMeter:\n","    \"\"\"Keep track of average values over time.\n","\n","    Adapted from:\n","        > https://github.com/pytorch/examples/blob/master/imagenet/main.py\n","    \"\"\"\n","    def __init__(self):\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def reset(self):\n","        \"\"\"Reset meter.\"\"\"\n","        self.__init__()\n","\n","    def update(self, val, num_samples=1):\n","        \"\"\"Update meter with new value `val`, the average of `num` samples.\n","\n","        Args:\n","            val (float): Average value to update the meter with.\n","            num_samples (int): Number of samples that were averaged to\n","                produce `val`.\n","        \"\"\"\n","        self.count += num_samples\n","        self.sum += val * num_samples\n","        self.avg = self.sum / self.count\n","\n","\n","def load_model(model, checkpoint_path, gpu_ids, return_step=True):\n","    \"\"\"Load model parameters from disk.\n","\n","    Args:\n","        model (torch.nn.DataParallel): Load parameters into this model.\n","        checkpoint_path (str): Path to checkpoint to load.\n","        gpu_ids (list): GPU IDs for DataParallel.\n","        return_step (bool): Also return the step at which checkpoint was saved.\n","\n","    Returns:\n","        model (torch.nn.DataParallel): Model loaded from checkpoint.\n","        step (int): Step at which checkpoint was saved. Only if `return_step`.\n","    \"\"\"\n","    device = f\"cuda:{gpu_ids[0] if gpu_ids else 'cpu'}\"\n","    ckpt_dict = torch.load(checkpoint_path, map_location=device)\n","\n","    # Build model, load parameters\n","    model.load_state_dict(ckpt_dict['model_state'])\n","\n","    if return_step:\n","        step = ckpt_dict['step']\n","        return model, step\n","\n","    return model\n","\n","def get_logger(log_dir, name):\n","    \"\"\"Get a `logging.Logger` instance that prints to the console\n","    and an auxiliary file.\n","\n","    Args:\n","        log_dir (str): Directory in which to create the log file.\n","        name (str): Name to identify the logs.\n","\n","    Returns:\n","        logger (logging.Logger): Logger instance for logging events.\n","    \"\"\"\n","    class StreamHandlerWithTQDM(logging.Handler):\n","        \"\"\"Let `logging` print without breaking `tqdm` progress bars.\n","\n","        See Also:\n","            > https://stackoverflow.com/questions/38543506\n","        \"\"\"\n","        def emit(self, record):\n","            try:\n","                msg = self.format(record)\n","                tqdm.tqdm.write(msg)\n","                self.flush()\n","            except (KeyboardInterrupt, SystemExit):\n","                raise\n","            except:\n","                self.handleError(record)\n","\n","    # Create logger\n","    logger = logging.getLogger(name)\n","    logger.setLevel(logging.DEBUG)\n","\n","    # Log everything (i.e., DEBUG level and above) to a file\n","    log_path = os.path.join(log_dir, 'log.txt')\n","    file_handler = logging.FileHandler(log_path)\n","    file_handler.setLevel(logging.DEBUG)\n","\n","    # Log everything except DEBUG level (i.e., INFO level and above) to console\n","    console_handler = StreamHandlerWithTQDM()\n","    console_handler.setLevel(logging.INFO)\n","\n","    # Create format for the logs\n","    file_formatter = logging.Formatter('[%(asctime)s] %(message)s',\n","                                       datefmt='%m.%d.%y %H:%M:%S')\n","    file_handler.setFormatter(file_formatter)\n","    console_formatter = logging.Formatter('[%(asctime)s] %(message)s',\n","                                          datefmt='%m.%d.%y %H:%M:%S')\n","    console_handler.setFormatter(console_formatter)\n","\n","    # add the handlers to the logger\n","    logger.addHandler(file_handler)\n","    logger.addHandler(console_handler)\n","\n","    return logger"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"yuD-2ZH5EDV1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559589777,"user_tz":240,"elapsed":278,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["class BertFineTune(nn.Module):\n","    def __init__(self):\n","        super(BertFineTune, self).__init__()\n","        self.embed_model = BertModel.from_pretrained('bert-base-uncased')\n","        \n","        # initial Feed Forward Network with same size and tanh activation, and initial dropout\n","        self.dense = nn.Linear(768, 768)\n","        self.initial_activation = nn.Tanh()\n","        self.dropout = nn.Dropout(p=0.1)\n","        \n","        # stack more layer for better fitting and dropout\n","        self.fc_1 = nn.Linear(768, 256)\n","        self.tanh1 = nn.Tanh()\n","        self.dropout2 = nn.Dropout(p=0.1)\n","\n","        # stack another layer\n","        self.fc_2 = nn.Linear(256, 128)\n","        self.tanh2 = nn.Tanh()\n","\n","        # does classification\n","        self.classifier = nn.Linear(128, 5)\n","\n","        # layers initialization\n","        nn.init.xavier_uniform_(self.dense.weight)  # layer initialization\n","        nn.init.xavier_uniform_(self.fc_1.weight)  # layer initialization\n","        nn.init.xavier_uniform_(self.fc_2.weight)  # layer initialization\n","        nn.init.xavier_uniform_(self.classifier.weight)  # layer initialization\n","\n","        # If using BertForSequenceClassification\n","        # self.softmax_layer = nn.LogSoftmax(dim = 1)  # uses logsoftmax for NLL loss instead of normal softmax\n","        # self.embed_model_sequence = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 5, \n","        #                                               output_attentions = False, output_hidden_states = False)\n","\n","\n","    def forward(self, x, seg_id_tensor, attnmask_tensor):\n","        # use bert to output embeddings\n","        # take the BERT embedding\n","        # bert_output[0] = last_layer_embedding  (batch_size, seq_len, hidden_size)\n","        # bert_output[1] = pooler_output, [CLS] embedding further preprocessed by linear and Tanh layers\n","        # bert_output[2] = tuple of length 13 (one for output of embedding layer and 12 output for each layer in the transformer) \n","        bert_output = self.embed_model(x, token_type_ids=seg_id_tensor, attention_mask=attnmask_tensor)\n","        \n","        # sequence_output size = batch_size x sequence_length x hidden_size\n","        sequence_output = bert_output[0]\n","\n","        # get embedding of [CLS] token\n","        cls_embed = sequence_output[:, 0, :] # take CLS embedding\n","        \n","        # post process the embedding layer by applying dense layer and tanh activation\n","        pooled_output = self.dense(cls_embed) # take linear layer\n","        pooled_output = self.initial_activation(pooled_output) # take activation\n","\n","        # perform dropout and stack linear layers and tanh afterwards \n","        after_dropout1 = self.dropout(pooled_output)\n","        \n","        linear1 = self.fc_1(after_dropout1)\n","        tanh1 = self.tanh1(linear1)\n","        after_dropout2 = self.dropout2(tanh1)\n","        linear2 = self.fc_2(after_dropout2)\n","        tanh2 = self.tanh2(linear2)\n","\n","        # do classification\n","        logits = self.classifier(tanh2)\n","        \n","        # if using BertForSequenceClassificatioin\n","        # pooled_output = bert_output[1]\n","        # loss, logits = self.embed_model_sequence(x, \n","        #                      token_type_ids=seg_id_tensor, \n","        #                      attention_mask=attnmask_tensor, \n","        #                      labels=labels)\n","                \n","        return logits"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2y6iHxmEDh_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559590171,"user_tz":240,"elapsed":148,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def get_prediction(review_ids, log_softmax_score):\n","    \"\"\"\n","    review_ids (int): Tensor of Review example IDs.\n","    log_softmax_score (list): tensor of log likehood scores (take max to get prediction)\n","    \"\"\"\n","    maxs = torch.argmax(log_softmax_score, dim = 1)\n","\n","    pred_dict = {}\n","    for id, max_val in zip(review_ids, maxs):\n","        pred_dict[id.item()] = max_val.item() \n","    return pred_dict"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"G1yaVmjxUxPl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559590755,"user_tz":240,"elapsed":225,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def evaluate_dict(gold_dict, pred_dict):\n","    sum_acc = 0\n","    sum_sentiment = 0\n","    total = 0\n","    all_preds = []\n","    all_gold = []\n","    \n","    for key, value in pred_dict.items():\n","        total += 1\n","        ground_truths = gold_dict[key]\n","        prediction = value\n","        if ground_truths == prediction:\n","            sum_acc += 1\n","\n","        # get sentiment correct\n","        if (int(prediction) == 0 or int(prediction) == 1) and (int(ground_truths) == 0 or int(ground_truths) == 1):  # Negative\n","            sum_sentiment += 1\n","        elif (int(prediction) == 2) and (int(ground_truths) == 2): # Neutral\n","            sum_sentiment += 1\n","        elif (int(prediction) == 3 or int(prediction) == 4) and (int(ground_truths) == 3 or int(ground_truths) == 4): # Positive\n","            sum_sentiment += 1\n","        \n","        all_preds.append(int(prediction))\n","        all_gold.append(int(ground_truths))\n","\n","    recallscore = recall_score(all_gold, all_preds, average='macro')\n","    precisionscore = precision_score(all_gold, all_preds, average = 'macro')\n","    f1score = f1_score(all_gold, all_preds, average='macro')\n","\n","    eval_dict = {'acc': 100. * sum_acc / total,\n","                 'sentiment_acc': 100. * sum_sentiment / total,\n","                 'recall': 100. * recallscore,\n","                 'precision': 100. * precisionscore, \n","                 'f1_score': 100. * f1score}\n","\n","    return eval_dict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"L4N_JVksUzHi","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559591664,"user_tz":240,"elapsed":260,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def evaluate(model, data_loader, eval_file, device):\n","    nll_meter = AverageMeter()\n","\n","    model.eval()\n","    pred_dict = {}\n","\n","    # get all true labels for ratings\n","    test_dataset = np.load(eval_file)\n","    true_labels = torch.from_numpy(test_dataset['rating']).long()\n","    uniq_ids = torch.from_numpy(test_dataset['ids']).long()\n","    true_labels = true_labels - 1 ## Need to subtract 1 because classes need to be 0 to n_classes - 1\n","    gold_dict = {}\n","    for true, ids in zip(true_labels, uniq_ids):\n","        gold_dict[ids.item()] = true.item()\n","\n","    with torch.no_grad(), tqdm.notebook.tqdm(total=len(data_loader.dataset), position=1, leave=True) as progress_bar:\n","        for text, attnmask, seg_id, rating, ids  in data_loader:\n","            # Setup for forward\n","            text = text.to(device)\n","            attnmask = attnmask.to(device)\n","            seg_id = seg_id.to(device)\n","            batch_size = text.size(0)\n","            ids = ids.to(device)\n","\n","            # rating needs to be 0 to num_classes - 1\n","            rating = rating - 1\n","            rating = rating.to(device)\n","\n","            # Forward\n","            logits = model(text, seg_id, attnmask)\n","            loss_fct = nn.CrossEntropyLoss()  # nn.CrossEntropyLoss = nn.Log_SoftMax + nn.NLL_LOSS\n","            loss = loss_fct(logits.view(-1, 5), rating.view(-1))\n","            \n","            nll_meter.update(loss.item(), batch_size)\n","\n","            # Get maximum prediction for prediction\n","            preds = get_prediction(ids, logits)\n","            pred_dict.update(preds)\n","\n","            # Log info\n","            progress_bar.update(batch_size)\n","            progress_bar.set_postfix(NLL=nll_meter.avg)\n","\n","    model.train()\n","\n","    results = evaluate_dict(gold_dict, pred_dict)\n","    results_list = [('NLL', nll_meter.avg),\n","                    ('acc', results['acc']),\n","                    ('sentiment_acc', results['sentiment_acc']),\n","                    ('precision', results['precision']),\n","                    ('recall', results['recall']),\n","                    ('f1_score', results['f1_score'])\n","                    ]\n","\n","    results = OrderedDict(results_list)\n","    return results, pred_dict"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"uCMkPHiUUy_k","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559592188,"user_tz":240,"elapsed":200,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def visualize(tbx, pred_dict, eval_path, step, split, num_visuals):\n","    \"\"\"Visualize text examples to TensorBoard.\n","\n","    Args:\n","        tbx (tensorboardX.SummaryWriter): Summary writer.\n","        pred_dict (dict): dict of predictions of the form id -> pred.\n","        eval_path (str): Path to eval JSON file.\n","        step (int): Number of examples seen so far during training.\n","        split (str): Name of data split being visualized.\n","        num_visuals (int): Number of visuals to select at random from preds.\n","    \"\"\"\n","    if num_visuals <= 0:\n","        return\n","    if num_visuals > len(pred_dict):\n","        num_visuals = len(pred_dict)\n","\n","    visual_ids = np.random.choice(list(pred_dict), size=num_visuals, replace=False)\n","\n","    with open(eval_path, 'r') as eval_file:\n","        eval_dict = json.load(eval_file)\n","    for i, id_ in enumerate(visual_ids):\n","        pred = pred_dict[id_] + 1 # NEED POST PROCESSING BECAUSE WE SUBTRACTED TO COMPLY WITH LOSS LABELS (0, n_classes - 1)\n","        example = eval_dict[str(id_)]\n","        user_id = example['user_id']\n","        business_id = example['business_id']\n","        text = example['text']\n","        gold = int(example['rating'])\n","\n","        gold_sent = 'Negative' \n","        pred_sent = 'Negative'\n","\n","        if (int(pred) == 1 or int(pred) == 2):\n","            pred_sent = 'Negative'\n","        elif (int(pred) == 3):\n","            pred_sent = 'Neutral'\n","        elif (int(pred) == 4 or int(pred) == 5):\n","            pred_sent = 'Positive'\n","        \n","        if (int(gold) == 1 or int(gold) == 2):\n","            gold_sent = 'Negative'\n","        elif (int(gold) == 3):\n","            gold_sent = 'Neutral'\n","        elif (int(gold) == 4 or int(gold) == 5):\n","            gold_sent = 'Positive'\n","\n","\n","        tbl_fmt = (f'- **Reviews:** {text}\\n'\n","                   + f'- **Answer:** {gold}\\n'\n","                   + f'- **True Sentiment**: {gold_sent}\\n'\n","                   + f'- **Prediction:** {pred}\\n'\n","                   + f'- **Prediction Sentiment**: {pred_sent}')\n","        tbx.add_text(tag=f'{split}/{i+1}_of_{num_visuals}',\n","                     text_string=tbl_fmt,\n","                     global_step=step)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uhg0y0X0VlCy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596559592941,"user_tz":240,"elapsed":237,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def get_available_devices():\n","    \"\"\"Get IDs of all available GPUs.\n","\n","    Returns:\n","        device (torch.device): Main device (GPU 0 or CPU).\n","        gpu_ids (list): List of IDs of all GPUs that are available.\n","    \"\"\"\n","    gpu_ids = []\n","    if torch.cuda.is_available():\n","        gpu_ids += [gpu_id for gpu_id in range(torch.cuda.device_count())]\n","        device = torch.device(f'cuda:{gpu_ids[0]}')\n","        torch.cuda.set_device(device)\n","    else:\n","        device = torch.device('cpu')\n","\n","    return device, gpu_ids"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"6itEM6S_Uy2Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596560206018,"user_tz":240,"elapsed":4783,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"168288da-3a4c-4f6b-da25-b5257903d258"},"source":["save_dir = 'gdrive/My Drive/Yelp_Sentiment_Analysis/save/test/baseline-01'\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","\n","log = get_logger(save_dir, 'baseline')\n","tbx = SummaryWriter(save_dir)\n","log.info(f'Using random seed 224 ...')\n","\n","device, gpu_ids = get_available_devices()\n","model = load_model(BertFineTune(), 'gdrive/My Drive/Yelp_Sentiment_Analysis/save/train/baseline-01/step_180000.pth.tar', gpu_ids, return_step=False)\n","model = model.to('cuda:0')\n","model.eval()"],"execution_count":28,"outputs":[{"output_type":"stream","text":["[08.04.20 16:56:41] Using random seed 224 ...\n","[08.04.20 16:56:41] Using random seed 224 ...\n","[08.04.20 16:56:41] Using random seed 224 ...\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["BertFineTune(\n","  (embed_model): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dense): Linear(in_features=768, out_features=768, bias=True)\n","  (initial_activation): Tanh()\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (fc_1): Linear(in_features=768, out_features=256, bias=True)\n","  (tanh1): Tanh()\n","  (dropout2): Dropout(p=0.1, inplace=False)\n","  (fc_2): Linear(in_features=256, out_features=128, bias=True)\n","  (tanh2): Tanh()\n","  (classifier): Linear(in_features=128, out_features=5, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"_fGLIQlsUytS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":450,"referenced_widgets":["19e3b3199ac449438b573d6604cc57ae","64a6c643ce60426e9341f1466f59ae97","dc1e5cb0ca074c96aeb21edb82982be6","07faa577926a413f825de764bb6cb9b2","5e8cf5476b16415683b7e8d8cf8b7a1c","b42bc532fd754db19ce4f644f87d3d5b","6278828bba1841b2838bc943f609fd0d","b63ecf34c36b456cafcfdcbddfc72b4b"]},"executionInfo":{"status":"error","timestamp":1596561527005,"user_tz":240,"elapsed":427660,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"f6c52de9-2837-4245-961f-ba7d936a0f74"},"source":["epoch = 0\n","step = 0\n","device = 'cuda:0'\n","steps_till_eval = 0\n","\n","\n","with torch.no_grad(), tqdm.tqdm(total=len(dev_loader.dataset), position=0, leave=True) as progress_bar:\n","    for text, attnmask, seg_id, rating, ids in dev_loader:\n","        # Setup for forward\n","        text = text.to(device)\n","        attnmask = attnmask.to(device)\n","        seg_id = seg_id.to(device)\n","        rating = rating.to(device)\n","        batch_size = text.size(0)\n","\n","        # need ratings to be 0 to n_classes - 1 (can later transform it)\n","        rating = rating - 1\n","\n","        # Forward\n","        logits = model(text, seg_id, attnmask)\n","\n","        # ypred\n","        ypred = torch.argmax(logits, dim = 1)\n","\n","        # compute loss\n","        loss_fct = nn.CrossEntropyLoss()  # nn.CrossEntropyLoss = nn.Log_SoftMax + nn.NLL_LOSS\n","        loss = loss_fct(logits.view(-1, 5), rating.view(-1))\n","        loss_val = loss.item()\n","\n","        # Log info\n","        step += batch_size\n","        progress_bar.update(batch_size)\n","        progress_bar.set_postfix(epoch=epoch, NLL=loss_val)\n","        \n","        tbx.add_scalar('train/NLL', loss_val, step)\n","\n","\n","        steps_till_eval -= batch_size\n","        if steps_till_eval <= 0:\n","            steps_till_eval = 10000\n","\n","            # Evaluate and save checkpoint\n","            log.info(f'Evaluating at step {step}...')\n","            results, pred_dict = evaluate(model, dev_loader, 'gdrive/My Drive/Yelp_Sentiment_Analysis/test.npz', device)\n","            \n","            # Log to console\n","            results_str = ', '.join(f'{k}: {v:05.2f}' for k, v in results.items())\n","            log.info(f'Dev {results_str}')\n","\n","            # Log to TensorBoard\n","            log.info('Visualizing in TensorBoard...')\n","            for k, v in results.items():\n","                  tbx.add_scalar(f'dev/{k}', v, step)\n","\n","            visualize(tbx,\n","                      pred_dict=pred_dict,\n","                      eval_path='dataset/test.json',\n","                      step=step,\n","                      split='dev',\n","                      num_visuals=30)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["  0%|          | 16/10000 [00:00<10:04, 16.52it/s, NLL=0.726, epoch=0]"],"name":"stderr"},{"output_type":"stream","text":["[08.04.20 17:11:41] Evaluating at step 16...\n","[08.04.20 17:11:41] Evaluating at step 16...\n","[08.04.20 17:11:41] Evaluating at step 16...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19e3b3199ac449438b573d6604cc57ae","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["  0%|          | 16/10000 [06:57<10:04, 16.52it/s, NLL=0.726, epoch=0]"],"name":"stderr"},{"output_type":"stream","text":["\n","[08.04.20 17:18:37] Dev NLL: 00.78, acc: 66.33, sentiment_acc: 84.16, precision: 66.13, recall: 66.32, f1_score: 66.19\n","[08.04.20 17:18:37] Dev NLL: 00.78, acc: 66.33, sentiment_acc: 84.16, precision: 66.13, recall: 66.32, f1_score: 66.19\n","[08.04.20 17:18:37] Dev NLL: 00.78, acc: 66.33, sentiment_acc: 84.16, precision: 66.13, recall: 66.32, f1_score: 66.19\n","[08.04.20 17:18:37] Visualizing in TensorBoard...\n","[08.04.20 17:18:37] Visualizing in TensorBoard...\n","[08.04.20 17:18:37] Visualizing in TensorBoard...\n"],"name":"stdout"},{"output_type":"stream","text":["  2%|▏         | 224/10000 [07:07<5:10:53,  1.91s/it, NLL=0.953, epoch=0]\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-a900e252729b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# nn.CrossEntropyLoss = nn.Log_SoftMax + nn.NLL_LOSS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Log info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"sV92_EdgUykS","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jc9GmSpNUycg","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6rRxxPNUyUZ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-lUDzL4UyM6","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WMO4C1QSUyE3","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1G73TDKHUx9g","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3oEZnrB-Ux1i","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6XdGaVs6UxuB","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Um_FwPsEUxmG","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s6LLtsn8UxeB","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6A_K17ZNUxHp","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0pQHWP5eSIoD","colab_type":"code","colab":{}},"source":["def get_available_devices():\n","    \"\"\"Get IDs of all available GPUs.\n","\n","    Returns:\n","        device (torch.device): Main device (GPU 0 or CPU).\n","        gpu_ids (list): List of IDs of all GPUs that are available.\n","    \"\"\"\n","    gpu_ids = []\n","    if torch.cuda.is_available():\n","        gpu_ids += [gpu_id for gpu_id in range(torch.cuda.device_count())]\n","        device = torch.device(f'cuda:{gpu_ids[0]}')\n","        torch.cuda.set_device(device)\n","    else:\n","        device = torch.device('cpu')\n","\n","    return device, gpu_ids"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tn5GVBhOEDso","colab_type":"code","colab":{}},"source":["def main():\n","    device, gpu_ids = get_available_devices()\n","    model = load_model(model, 'gdrive/My Drive/Yelp_Sentiment_Analysis/save/train/baseline-01/step_180000.pth.tar', gpu_ids, return_step=False)\n","    model = model.to(device)\n","    model.eval()\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hy4kjYIqc0j0","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eOO_PotSVwep","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9-aOv4P4C6b7","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3Ui0DOVDZtn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596556312211,"user_tz":240,"elapsed":582,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"M_fFmKZMOxZZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596556313976,"user_tz":240,"elapsed":504,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"OZ6LCImJJqVL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596556316374,"user_tz":240,"elapsed":413,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"CMjbL2u2C-cq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596556318425,"user_tz":240,"elapsed":445,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"9STq9BVPOvm9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596556320993,"user_tz":240,"elapsed":452,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-U6qEmpJ1ro","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596556323573,"user_tz":240,"elapsed":477,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"vI9IsCZkJ7wo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596556326696,"user_tz":240,"elapsed":805,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"dCXjjejtH9HN","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZPFNHrRVF_AY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596556334222,"user_tz":240,"elapsed":803,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"sshT32C6SZbZ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MTbVaDOUsVnl","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o0Q9Qvt0GRvS","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FpKHTit6sV9W","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aT0GDfwJsV3k","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Pge2PniUByw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596558429709,"user_tz":240,"elapsed":795,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"g04jgxZnj8Yg","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_vbrQecloMk","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hY_FoxSflrcq","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}