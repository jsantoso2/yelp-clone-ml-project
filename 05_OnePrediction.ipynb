{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05_OnePrediction.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPpSMnG8C062byj/0vNyy3Y"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"7nWHsofSQcVx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1596724898766,"user_tz":240,"elapsed":2843,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"fc825662-d3f2-4b43-d4d3-350cc7e68742"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ey9EoCyDRClP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":595},"executionInfo":{"status":"ok","timestamp":1596724907022,"user_tz":240,"elapsed":11074,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"25086c9a-1e79-43fb-9253-78dc5dde9c6c"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 4.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 28.4MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 44.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 38.0MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=5fa704519bb9367684cca0ee31cc635aaa4d25386b06b9febb24c617b5daf6c8\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DVULomjaRIOR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1596724925202,"user_tz":240,"elapsed":29234,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"55c5b018-d3ee-4f7f-e1af-3200b79d0102"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cO43wP4yExre","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596724925207,"user_tz":240,"elapsed":29213,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MiNJrKdrEy1G","colab_type":"text"},"source":["**Prediction**"]},{"cell_type":"code","metadata":{"id":"-GpOpjbJEx3a","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596724930052,"user_tz":240,"elapsed":33713,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["import torch\n","import torch.nn as nn\n","from transformers import BertTokenizer, BertModel\n","\n","import re\n","import numpy as np\n","\n","np.random.seed(224)\n","torch.manual_seed(224)\n","torch.cuda.manual_seed_all(224)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqF_EyqPFbtK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596724930067,"user_tz":240,"elapsed":33045,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def clean_text(tokenizer, text):\n","    # basic text preprocessing\n","    text = text.replace(\"''\", '\" ').replace(\"``\", '\" ')  # replace the quotes \n","    text = text.replace(\"`\", \"'\") # backticks typo\n","    text = text.replace(\"\\\"\", \"\") # replace quotes\n","    text = text.replace(\"...\", \" \").replace(\". . .\", \" \").replace('..', ' ') # replace dots\n","    text = text.replace(\"\\n\", \" \") # replace new line chars\n","    text = re.sub(r'(?:http:|https:).*?(?=\\s)', '', text)  # remove url and website\n","    text = re.sub(r'www.*?(?=\\s)', '', text)  # remove url and website\n","\n","    list_to_replace = [':(', '=)', ':)', ':P', '-', ',,', ':', ';', '/', '+', '~', '_', '*', '(', ')', '&', '=', '@'] #replace the punctuations which are messy with empty\n","    for elem in list_to_replace:\n","        text = text.replace(elem, '')\n","    \n","    text = re.sub(r'\\!{2,}', '!', text) # duplicate punctuation\n","    text = re.sub(r'\\?{2,}', '?', text) # duplicate punctuation\n","    text = text.replace('?!', '?').replace('!?', '?') #replace slang punctuation with question\n","    text = re.sub(r'\\s(?:\\.|\\,)', '', text) # replace spaces before punctuation\n","    text = re.sub(r'([a-zA-Z?!])\\1\\1+', r'\\1', text) # removes repeated characters (Ex: Veryyyyy -> very)\n","    \n","    text = re.sub(r'\\s{2,}', ' ', text) # replace multiple spaces\n","    text = text.strip() # strips spaces\n","\n","    text = text.lower() # lower text\n","\n","    return text"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"fD2z1y9WI7gs","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596724930070,"user_tz":240,"elapsed":32503,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def pad_sent(tokenizer, raw_text, max_text_len = 350):  #token number 0 is [PAD]\n","    curr_text = \"[CLS] \" + raw_text  # add starting cls token\n","    tokenized_text = tokenizer.tokenize(curr_text) # tokenize            \n","    tokenized_ids = tokenizer.convert_tokens_to_ids(tokenized_text) # convert to ids\n","\n","    tokenized_ids = tokenized_ids[:max_text_len - 1]   # trim the reviews\n","    tokenized_ids.append(102) # add special token for [SEP]\n","    \n","    # get text length and padding\n","    curr_sent_len = len(tokenized_ids)\n","    remaining = max_text_len - curr_sent_len # words remaining for padding\n","\n","    # pad the input token\n","    tokenized_ids.extend([0] * remaining)  # pad the text to max_text_len\n","\n","    # create attention and segmented mask\n","    curr_attn = [1] * curr_sent_len  \n","    curr_attn.extend([0] * remaining)\n","    curr_seg_id = [0] * max_text_len\n","\n","    return tokenized_ids, curr_attn, curr_seg_id"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"TY0vR83l2B8L","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596724930073,"user_tz":240,"elapsed":32039,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def get_available_devices():\n","    \"\"\"Get IDs of all available GPUs.\n","\n","    Returns:\n","        device (torch.device): Main device (GPU 0 or CPU).\n","        gpu_ids (list): List of IDs of all GPUs that are available.\n","    \"\"\"\n","    gpu_ids = []\n","    if torch.cuda.is_available():\n","        gpu_ids += [gpu_id for gpu_id in range(torch.cuda.device_count())]\n","        device = torch.device(f'cuda:{gpu_ids[0]}')\n","        torch.cuda.set_device(device)\n","    else:\n","        device = torch.device('cpu')\n","\n","    return device, gpu_ids"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"nMYUl43rFb4g","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596724930075,"user_tz":240,"elapsed":31357,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["# #### USED ONLY IF WE LOAD .pth file from save_state_dict()\n","\n","# def load_model(model, checkpoint_path, gpu_ids, return_step=True):\n","#     \"\"\"Load model parameters from disk.\n","\n","#     Args:\n","#         model (torch.nn.DataParallel): Load parameters into this model.\n","#         checkpoint_path (str): Path to checkpoint to load.\n","#         gpu_ids (list): GPU IDs for DataParallel.\n","#         return_step (bool): Also return the step at which checkpoint was saved.\n","\n","#     Returns:\n","#         model (torch.nn.DataParallel): Model loaded from checkpoint.\n","#         step (int): Step at which checkpoint was saved. Only if `return_step`.\n","#     \"\"\"\n","#     device = \"cuda:\" + gpu_ids[0] if gpu_ids else 'cpu' \n","#     ckpt_dict = torch.load(checkpoint_path, map_location=device)\n","\n","#     # Build model, load parameters\n","#     model.load_state_dict(ckpt_dict['model_state'])\n","\n","#     if return_step:\n","#         step = ckpt_dict['step']\n","#         return model, step\n","\n","#     return model"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"l2fyKvHe2DwT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596724930077,"user_tz":240,"elapsed":30329,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["# ### USED ONLY IF WE LOAD .pth file from save_state_dict()\n","\n","# class BertFineTune(nn.Module):\n","#     def __init__(self):\n","#         super(BertFineTune, self).__init__()\n","#         self.embed_model = BertModel.from_pretrained('gdrive/My Drive/Yelp_Sentiment_Analysis/bert-base-uncased')\n","        \n","#         # initial Feed Forward Network with same size and tanh activation, and initial dropout\n","#         self.dense = nn.Linear(768, 768)\n","#         self.initial_activation = nn.Tanh()\n","#         self.dropout = nn.Dropout(p=0.1)\n","        \n","#         # stack more layer for better fitting and dropout\n","#         self.fc_1 = nn.Linear(768, 256)\n","#         self.tanh1 = nn.Tanh()\n","#         self.dropout2 = nn.Dropout(p=0.1)\n","\n","#         # stack another layer\n","#         self.fc_2 = nn.Linear(256, 128)\n","#         self.tanh2 = nn.Tanh()\n","\n","#         # does classification\n","#         self.classifier = nn.Linear(128, 5)\n","\n","#         # layers initialization\n","#         nn.init.xavier_uniform_(self.dense.weight)  # layer initialization\n","#         nn.init.xavier_uniform_(self.fc_1.weight)  # layer initialization\n","#         nn.init.xavier_uniform_(self.fc_2.weight)  # layer initialization\n","#         nn.init.xavier_uniform_(self.classifier.weight)  # layer initialization\n","\n","#     def forward(self, x, seg_id_tensor, attnmask_tensor):\n","#         # use bert to output embeddings\n","#         # take the BERT embedding\n","#         # bert_output[0] = last_layer_embedding  (batch_size, seq_len, hidden_size)\n","#         # bert_output[1] = pooler_output, [CLS] embedding further preprocessed by linear and Tanh layers\n","#         # bert_output[2] = tuple of length 13 (one for output of embedding layer and 12 output for each layer in the transformer) \n","#         bert_output = self.embed_model(x, token_type_ids=seg_id_tensor, attention_mask=attnmask_tensor)\n","        \n","#         # sequence_output size = batch_size x sequence_length x hidden_size\n","#         sequence_output = bert_output[0]\n","\n","#         # get embedding of [CLS] token\n","#         cls_embed = sequence_output[:, 0, :] # take CLS embedding\n","        \n","#         # post process the embedding layer by applying dense layer and tanh activation\n","#         pooled_output = self.dense(cls_embed) # take linear layer\n","#         pooled_output = self.initial_activation(pooled_output) # take activation\n","\n","#         # perform dropout and stack linear layers and tanh afterwards \n","#         after_dropout1 = self.dropout(pooled_output)\n","        \n","#         linear1 = self.fc_1(after_dropout1)\n","#         tanh1 = self.tanh1(linear1)\n","#         after_dropout2 = self.dropout2(tanh1)\n","#         linear2 = self.fc_2(after_dropout2)\n","#         tanh2 = self.tanh2(linear2)\n","\n","#         # do classification\n","#         logits = self.classifier(tanh2)\n","\n","#         return logits"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mt5R90j_SUd-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596725072717,"user_tz":240,"elapsed":288,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def setup_model():\n","    # create tokenizer\n","    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","    # tokenizer = BertTokenizer.from_pretrained('gdrive/My Drive/Yelp_Sentiment_Analysis/bert-base-uncased')\n","\n","    # load model\n","    device, gpu_ids = get_available_devices()\n","\n","    # load from final model\n","    model = torch.jit.load(\"gdrive/My Drive/Yelp_Sentiment_Analysis/best-model-180000.pth\")\n","\n","    # load from state_dict\n","    #model = load_model(BertFineTune(), 'gdrive/My Drive/Yelp_Sentiment_Analysis/save/train/baseline-01/step_180000.pth.tar', gpu_ids, return_step=False)\n","\n","    model = model.to(device)\n","    model.eval()\n","\n","    return tokenizer, model, device"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"2PruC7A03qc0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596725073501,"user_tz":240,"elapsed":318,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["def do_prediction(device, tokenizer, test_string):\n","          \n","    # test string + preprocess\n","    test_string = clean_text(tokenizer, test_string)\n","    tokenized_ids, curr_attn, curr_seg_id = pad_sent(tokenizer, test_string)\n","\n","\n","    with torch.no_grad():\n","        # Setup for forward\n","        text = torch.tensor(tokenized_ids).to(device)\n","        attnmask = torch.tensor(curr_attn).to(device)\n","        seg_id = torch.tensor(curr_seg_id).to(device)\n","\n","        text = torch.reshape(text, (1, -1))\n","        attnmask = torch.reshape(attnmask, (1, -1))\n","        seg_id = torch.reshape(seg_id, (1,-1))\n","\n","        # Forward\n","        logits = model(text, seg_id, attnmask)\n","\n","        # ypred\n","        ypred = torch.argmax(logits, dim = 1)\n","\n","        print('rating is: ', ypred.item() + 1, '*')"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fid_Ze71NGrk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596725075352,"user_tz":240,"elapsed":1576,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["import time\n","start = time.time()\n","tokenizer, model, device = setup_model()\n","end = time.time()"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"m3C9TsEPF7Ku","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596725076346,"user_tz":240,"elapsed":217,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"ce2129d7-431d-46d2-f612-e9479e69aade"},"source":["end - start"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0666265487670898"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"nIlpy8OfTJ9X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596725079644,"user_tz":240,"elapsed":2045,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"bbb534be-a434-4869-8416-8d9effd8baf1"},"source":["start = time.time()\n","test_string = 'I Love the food here its really good'\n","do_prediction(device, tokenizer, test_string)\n","end = time.time()"],"execution_count":24,"outputs":[{"output_type":"stream","text":["rating is:  5 *\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bmSqzknWHYb7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596725080532,"user_tz":240,"elapsed":391,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"0ed555a8-4024-4d46-b546-0a1228054bb0"},"source":["end - start"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.7071433067321777"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"Z9n2Mhb_Gx2Y","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596724395995,"user_tz":240,"elapsed":300,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":[""],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"zWn03ZGZMK-P","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"650wW2lBM2IZ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ns_1M8nHM2wE","colab_type":"text"},"source":["**Saving Model As JIT**"]},{"cell_type":"code","metadata":{"id":"yNRaX-tqMLLs","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596724595782,"user_tz":240,"elapsed":440,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["# # test string + preprocess\n","# test_string = 'I hate this good'\n","# test_string = clean_text(tokenizer, test_string)\n","# tokenized_ids, curr_attn, curr_seg_id = pad_sent(tokenizer, test_string)\n","\n","# text = torch.tensor(tokenized_ids).to(device)\n","# attnmask = torch.tensor(curr_attn).to(device)\n","# seg_id = torch.tensor(curr_seg_id).to(device)\n","\n","# text = torch.reshape(text, (1, -1))\n","# attnmask = torch.reshape(attnmask, (1, -1))\n","# seg_id = torch.reshape(seg_id, (1,-1))"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"IcH_8z6QTKLc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596724606906,"user_tz":240,"elapsed":10451,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["# torch.jit.save(torch.jit.trace(model, (text, seg_id, attnmask)), \"gdrive/My Drive/Yelp_Sentiment_Analysis/best-model-180000.pth\")"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZFjB6JxYTKhZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596724625153,"user_tz":240,"elapsed":1187,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}}},"source":["# loaded_model = torch.jit.load(\"gdrive/My Drive/Yelp_Sentiment_Analysis/best-model-180000.pth\")"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"H16_RnMtUDt5","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w6R1wKLCJwWb","colab_type":"text"},"source":["**Saving Base Model**"]},{"cell_type":"code","metadata":{"id":"wY-7ZH-oUEGx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1596572501941,"user_tz":240,"elapsed":491,"user":{"displayName":"Jonathan Irvin Santoso","photoUrl":"","userId":"15896224113783383038"}},"outputId":"4dcfa043-9c5e-4111-e836-ba5ba801d066"},"source":["# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","# tokenizer.save_pretrained('gdrive/My Drive/Yelp_Sentiment_Analysis/bert-base-uncased')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('gdrive/My Drive/Yelp_Sentiment_Analysis/bert-base-uncased/vocab.txt',\n"," 'gdrive/My Drive/Yelp_Sentiment_Analysis/bert-base-uncased/special_tokens_map.json',\n"," 'gdrive/My Drive/Yelp_Sentiment_Analysis/bert-base-uncased/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"yuD-2ZH5EDV1","colab_type":"code","colab":{}},"source":["# model = BertModel.from_pretrained('bert-base-uncased')\n","# model.save_pretrained('gdrive/My Drive/Yelp_Sentiment_Analysis/bert-base-uncased')"],"execution_count":null,"outputs":[]}]}